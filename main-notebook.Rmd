---
title: "Sistemi di raccomandazione in R"
output: html_notebook
---

### Introduzione
I **sistemi di raccomandazione** sono dei sistemi software che permettono di predire le preferenze di un utente basandoci sulle preferenze espresse dall'utente in passato.  
A differenza dei sistemi tradizionali, essi possono predirre il gradimento dell'utente anche per oggetti rari, evitando il cosidetto fenomeno **long-tail**.  
Un sistema di raccomandazione è strutturato in una matrice chiamata **matrice di utilità**, avente:  
- nelle righe, gli utenti del sistema.  
- nelle colonne, gli oggetti da valutare.  
- nelle celle, la valutazione dell'oggetto nella colonna `j` relativa all'utente nella riga `i`.  

I sistemi di raccomandazione possono diversi in due categorie:  
-  **content-based**: ad ogni utente è associato un profilo che verrà utilizzato per effettuare le predizioni sugli item.  
- **collaborative-filtering**: le predizioni sugli item vengono fatte basandoci su utenti simili (nel caso di **user-based** collaborative filtering) oppure su item simili (nel caso di **item-based** collaborative filtering).  

### Obbiettivo
Creeremo diversi sistemi di raccomandazione e ne confronteremo le prestazioni. Useremo anche un sistema personalizzato che tenga in considerazione delle data in cui è stata lasciata la valutazione.  
Useremo questo [dataset](https://grouplens.org/datasets/movielens/latest/) per generare i sistemi. Al suo interno sono presenti due tabelle `.csv`:  
- `movies.csv`: contiene l'elenco dei film, con i campi `movieId`, `title` e `genres`.  
- `ratings.csv`: contiene l'elenco delle valutazione relative agli utenti, con i campi `userId`, `movieId`, `rating`, `timestamp`.  

### Preparazione dell'ambiente
All'interno del nostro progetto, useremo diverse librerie:  
- [`reshape2`](https://cran.r-project.org/web/packages/reshape2/index.html), permette di creare un data frame oppure una matrice partendo da una lista.  
- [`reccomenderlab`](https://cran.r-project.org/web/packages/recommenderlab/index.html), permette la creazione e la valutazione dei sistemi di raccomandazione.  

Installiamo quindi i pacchetti necessari per il funzionamento:
```{r}
# install.packages("reshape2")
# install.packages("recommenderlab")
# install.packages("sqldf")
```
ed importiamolo nel progetto:
```{r}
library("reshape2")
library("recommenderlab")
library("sqldf")
```
Adesso, carichiamo i dataset all'interno del progetto usando la funzione `read.csv`:
```{r}
movie_dataset <- read.csv("movie-dataset/movies.csv",  sep = ",")
rating_dataset <- read.csv("movie-dataset/ratings.csv", sep = ",")
```

### Analisi del dataset

Una volta caricati i dati, verifichiamone l'**integrità**.  
L'integrità dei dati è essenziale per garantire l'affidabilità dei risultati dell'analisi.  
La presenza di dati incompleti, come i valori `NA`, potrebbero influenzare la validità dei risultati dell'analisi.  
All'interno di R è presente la funzione `complete.cases` che restituisce una matrice di valori booleani con:  
- TRUE, nel caso in cui i dati sono completi.  
- FALSE, nel caso in cui i dati sono incompleti.  
Questa funzione può essere usata per effettuare una **pulizia** sui dati:  
```{r}
movie_dataset <- movie_dataset[complete.cases(movie_dataset), ]
rating_dataset <- rating_dataset[complete.cases(rating_dataset), ]
```

### Qualità dei dati

Dalla matrice base, prendiamo solo una parte piccola di valori:
```{r}
given <- 15
```

Salviamo i dati degli utenti in un data frame apposito:
```{r}
users_array <- unique(rating_dataset[, 1])
users_dataset <- data.frame(
  userId = users_array, 
  median = replicate(length(users_array), 0), 
  weigthed_median = replicate(length(users_array), 0)
)
```

Calcoliamo la media per utente:
```{r}
for (user_index in 1:length(users_array)) {
  user <- users_array[user_index]
  single_user_dataset <- rating_dataset[rating_dataset[, 1] == user, ]
  single_user_last_rating <- max(single_user_dataset[, 4])
  single_user_sum <- sum(single_user_dataset[, 3])
  single_user_weigth_sum <- 0
  for (rating_index in 1:nrow(single_user_dataset)) {
    row <- single_user_dataset[rating_index, ]
    weigth <- row[, 4] / single_user_last_rating
    weigthed_rating <- row[, 3] * weigth
    single_user_weigth_sum <- single_user_weigth_sum + weigthed_rating
  }
  single_user_median <- single_user_sum / nrow(single_user_dataset)
  single_user_weigth_median <- single_user_weigth_sum / nrow(single_user_dataset)
  users_dataset[user_index, 2] <- single_user_median
  users_dataset[user_index, 3] <- single_user_weigth_median
}
```

Pritiamo l'analisi del dataset:
```{r}
hist(
  rating_dataset[, 3],
  breaks = 5,
  main = 'Frequency of registered ratings', 
  xlab = 'Ratings', 
  col = '#FDDBC7',
  border = '#F4A582'
)
```

Printiamo il rating medio, pesato e non:
```{r}
par(mfrow = c(1,2))
hist(
  users_dataset[, 2],
  breaks = 5,
  main = 'Average non-weigthed mean ratings', 
  xlab = 'Mean ratings',
  col = '#4393C3',
  border = '#2166AC'
)
hist(
  users_dataset[, 3],
  breaks = 5,
  main = 'Average weigthed mean ratings', 
  xlab = 'Mean ratings',
  col = '#D6604D',
  border = '#B2182B'
)
```



Dopo aver ottenuto un dataset pulito, possiamo procedere alla creazione della matrice di utilità.  
Essendo il nostro dataset organizzato per righe, è necessario effettuare una conversione.  
Nel pacchetto reshape2 è inclusa la funzione `acast` che prendendo in input le liste di valori, la formula per creare righe / colonne e il nome della lista relativa valore da inserire nelle celle, ci restituisce una matrice.  
Nel nostro caso, `rating_dataset` rappresenta il dataset con tutte le colonne, `userId~movieId`rappresenta la formula per ottenere rispettivamente nelle righe gli utenti e nelle colonne i film, il valore `rating` rappresenta il valore nelle celle.   

Utilizziamola nel nostro caso:
```{r}
converted_matrix <- acast(rating_dataset, userId~movieId, value.var = "rating")
```

Adesso, la possiamo usare come oggetto di tipo `realRatingMatrix`, che reccomenderlab riconosce:
```{r}
rating_matrix <- as(converted_matrix, "realRatingMatrix")
```

Vediamo diversi modi per addestrare il sistema di raccomandazione:
```{r}
split_matrix <- evaluationScheme(
  data = rating_matrix, 
  method = "split", 
  train = 0.8, 
  given = given, 
  goodRating = 3, 
  k = 4
)
k_fold_matrix <- evaluationScheme(
  data = rating_matrix, 
  method = "cross-validation",
  k = 4, 
  given = given, 
  goodRating = 3
)
```

Di seguito, facciamo l'elenco dei metodi di valutazione che possiamo avere:
```{r}
models_list = list(
  "UBCF:Cosine:Split" = list(name="UBCF", data=split_matrix, params=list(method ="cosine", normalize="center")),
  "UBCF:Pearson:Split" = list(name="UBCF", data=split_matrix, params=list(method ="pearson", normalize="center")),
  "IBCF:Cosine:Split" = list(name="IBCF", data=split_matrix, params=list(method ="cosine", normalize="center")),
  "IBCF:Pearson:Split" = list(name="IBCF", data=split_matrix, params=list(method ="pearson", normalize="center")),
  "UBCF:Cosine:K-Fold" = list(name="UBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="center")),
  "UBCF:Pearson:K-Fold" = list(name="UBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="center")),
  "IBCF:Cosine:K-Fold" = list(name="IBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="center")),
  "IBCF:Pearson:K-Fold" = list(name="IBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="center")),
  "UBCF:Cosine:Split:Z" = list(name="UBCF", data=split_matrix, params=list(method ="cosine", normalize="z-score")),
  "UBCF:Pearson:Split:Z" = list(name="UBCF", data=split_matrix, params=list(method ="pearson", normalize="z-score")),
  "IBCF:Cosine:Split:Z" = list(name="IBCF", data=split_matrix, params=list(method ="cosine", normalize="z-score")),
  "IBCF:Pearson:Split:Z" = list(name="IBCF", data=split_matrix, params=list(method ="pearson", normalize="z-score")),
  "UBCF:Cosine:K-Fold:Z" = list(name="UBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="z-score")),
  "UBCF:Pearson:K-Fold:Z" = list(name="UBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="z-score")),
  "IBCF:Cosine:K-Fold:Z" = list(name="IBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="z-score")),
  "IBCF:Pearson:K-Fold:Z" = list(name="IBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="z-score"))
)
```

Creiamo una funzione per vedere gli errori:
```{r}
get_model_results <- function(settings) {
 model <- Recommender(getData(settings$data, "train"), settings$name, parameter = settings$params)
 test <- predict(model, getData(settings$data, "known"), type="ratings")
 error <- calcPredictionAccuracy(test, getData(settings$data, "unknown"))
 return(error)
}
```

Richiamiamola su tutti i metodi elencati fino ad ora:
```{r}
for (model_name in names(models_list)) {
  settings <- models_list[[model_name]]
  model_error <- get_model_results(settings)
  models_list[[model_name]] <- c(settings, results=model_error)
}
```

Elenchiamo i risultati:
```{r}
for (model_name in names(models_list)) {
  print(paste("Printing results for:", model_name))
  print(paste("RSME:", models_list[[model_name]]$results.RMSE))
  print(paste("MSE:", models_list[[model_name]]$results.MSE))
  print(paste("MAE:", models_list[[model_name]]$results.MAE))
}
```

Vedi altre risorse:  
- [Reccomendation 101](https://www.r-bloggers.com/2014/12/recommender-systems-101-a-step-by-step-practical-example-in-r/)  
- [Data Mania](https://www.data-mania.com/blog/how-to-build-a-recommendation-engine-in-r/)  
- [Res 1](https://rpubs.com/robertwsellers/IS643_Project_2)   
- [Res 2](https://rpubs.com/dhairavc/628480)  
- [Res 3](https://www.linkedin.com/pulse/create-recommendation-engine-using-r-simple-steps-minta-thomas/)  
- [Weigth median](https://stats.stackexchange.com/questions/196653/assigning-more-weight-to-more-recent-observations-in-regression)

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
