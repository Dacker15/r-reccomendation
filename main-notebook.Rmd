---
title: "Sistemi di raccomandazione in R"
output: html_notebook
---

### Introduzione
I **sistemi di raccomandazione** sono dei sistemi software che permettono di predire le preferenze di un utente basandoci sulle preferenze espresse dall'utente in passato.  
A differenza dei sistemi tradizionali, essi possono predire il gradimento dell'utente anche per oggetti rari, evitando il cosiddetto fenomeno **long-tail**.  
Un sistema di raccomandazione è strutturato in una matrice chiamata **matrice di utilità**, avente:  
- nelle righe, gli utenti del sistema.  
- nelle colonne, gli oggetti da valutare.  
- nelle celle, la valutazione dell'oggetto nella colonna `j` relativa all'utente nella riga `i`.  

I sistemi di raccomandazione possono diversi in due categorie:  
-  **content-based**: ad ogni utente è associato un profilo che verrà utilizzato per effettuare le predizioni sugli item.  
- **collaborative-filtering**: le predizioni sugli item vengono fatte basandoci su utenti simili (nel caso di **user-based** collaborative filtering) oppure su item simili (nel caso di **item-based** collaborative filtering).  

### Obbiettivo
Creeremo diversi sistemi di raccomandazione e ne confronteremo le prestazioni. Useremo anche un sistema personalizzato che tenga in considerazione delle data in cui è stata lasciata la valutazione.  
Useremo questo [dataset](https://grouplens.org/datasets/movielens/1m/) per generare i sistemi. Al suo interno sono presenti due tabelle `.csv`:  
- `movies.csv`: contiene l'elenco dei film, con i campi `movieId`, `title` e `genres`.  
- `ratings.csv`: contiene l'elenco delle valutazione relative agli utenti, con i campi `userId`, `movieId`, `rating`, `timestamp`.  
- `users.csv`: contiene l'elenco degli utenti e le loro informazioni, con i campi `userId`, `gender`, `age`, `occupation`, `zip`.  

### Preparazione dell'ambiente
All'interno del nostro progetto, useremo diverse librerie:  
- [`reshape2`](https://cran.r-project.org/web/packages/reshape2/index.html), permette di creare un data frame oppure una matrice partendo da una lista.  
- [`reccomenderlab`](https://cran.r-project.org/web/packages/recommenderlab/index.html), permette la creazione e la valutazione dei sistemi di raccomandazione.  
- [`sqldf`](https://cran.r-project.org/web/packages/sqldf/index.html), permette la manipolazione di data frame usando la sintassi SQL.  

Importiamo i pacchetti all'interno del progetto:
```{r}
library("reshape2")
library("recommenderlab")
library("sqldf")
```
Adesso, carichiamo i dataset all'interno del progetto usando la funzione `read.csv`:
```{r}
movie_dataset <- read.csv("movie-dataset/movies.csv",  sep = ",")
rating_dataset <- read.csv("movie-dataset/ratings.csv", sep = ",")
```

### Pulizia del dataset

Una volta caricati i dati, verifichiamone l'**integrità**.  
L'integrità dei dati è essenziale per garantire l'affidabilità dei risultati dell'analisi.  
La presenza di dati incompleti, come i valori `NA`, potrebbero influenzare la validità dei risultati dell'analisi.  
All'interno di R è presente la funzione `complete.cases` che restituisce una matrice di valori booleani con:  
- TRUE, nel caso in cui i dati sono completi.  
- FALSE, nel caso in cui i dati sono incompleti.  
Questa funzione può essere usata per effettuare una **pulizia** sui dati:
```{r}
movie_dataset <- movie_dataset[complete.cases(movie_dataset), ]
rating_dataset <- rating_dataset[complete.cases(rating_dataset), ]
```

Scartati i dati nulli o incompleti, prendiamo in considerazione solo una porzione dei dati, in particolare consideriamo solo:  
- gli utenti che hanno valutato **almeno 300 film**.  
- i film che sono stati valutati **almeno 600 volte**.  
Questo condizione ci permette di escludere utenti e film che non sono stati valutati abbastanza e per cui **non sono presenti abbastanza dati per poter effettuare predizioni sufficientemente accurate**.  
Filtriamo quindi il dataset delle valutazione in base alle condizione sopra citate:  
```{r}
grouped_users <- sqldf("SELECT userId, COUNT(movieId) as count_user FROM rating_dataset GROUP BY userId")
grouped_movies <- sqldf("SELECT movieId, COUNT(userId) as count_movie FROM rating_dataset GROUP BY movieId")
rating_dataset <- sqldf(
  "SELECT rating_dataset.userId, rating_dataset.movieId, rating, timestamp, count_user, count_movie FROM rating_dataset 
   LEFT JOIN grouped_users ON grouped_users.userId = rating_dataset.userId
   LEFT JOIN grouped_movies ON grouped_movies.movieId = rating_dataset.movieId
   WHERE count_user > 300 AND count_movie > 600
  "
)
given <- 240
```

### Analisi del dataset

Dopo un primo filtro, possiamo caricare i dati relativi agli utenti:
```{r}
users_dataset <- read.csv('movie-dataset/users.csv')
```

Da questi, leviamo gli utenti che non sono più inclusi nelle valutazioni:
```{r}
users_dataset <- sqldf("
  SELECT userId, gender, age, occupation, zip FROM users_dataset
  WHERE userId IN (SELECT DISTINCT(userId) FROM rating_dataset)
")
```

Una volta rimosso dal dataset degli utenti che non hanno fatto recensito abbastanza film, aggiungiamo al data frame le seguenti colonne:  
- `mean`, contiene la media delle valutazione lasciate dall'utente.  
- `weighted_mean`, contiene la media pesata con il timestamp delle valutazioni lasciate dall'utente.  
- `ratings_range`, contiene la differenza fra la prima valutazione e l'ultima valutazione lasciata dall'utente.  
- `mean_diff`, contiene la differenza fra la media aritmetica e la media pesata delle valutazioni.  

Gli ultimi due campi ci permetterrano di dimostrare se esiste una correlazione fra la differenze fra le media aritmetica ed il range temporale in cui sono state lasciate le valutazione.  
In pratica, vogliamo verificare se in un intervallo temporale più ampio, la differenza fra la media aritmetica e quella pesata aumenta.

```{r}
users_dataset['mean'] <- replicate(nrow(users_dataset), 0)
users_dataset['weigthed_mean'] <- replicate(nrow(users_dataset), 0)
users_dataset['ratings_range'] <- replicate(nrow(users_dataset), 0)
users_dataset['mean_diff'] <- replicate(nrow(users_dataset), 0)
```

Una volta aggiunti i campi, effettuiamo tutti i calcoli necessari per popolare i campi:
```{r}
for (user_index in 1:nrow(users_dataset)) {
  user <- users_dataset[user_index, 'userId']
  single_user_dataset <- rating_dataset[rating_dataset[, 'userId'] == user, ]
  single_user_first_rating <- min(single_user_dataset[, 'timestamp'])
  single_user_last_rating <- max(single_user_dataset[, 'timestamp'])
  single_user_time_range <- single_user_last_rating - single_user_first_rating
  single_user_sum <- sum(single_user_dataset[, 'rating'])
  single_user_weigth_sum <- 0
  for (rating_index in 1:nrow(single_user_dataset)) {
    row <- single_user_dataset[rating_index, ]
    weigth <- row[, 'timestamp'] / single_user_last_rating
    weigthed_rating <- row[, 'rating'] * weigth
    single_user_weigth_sum <- single_user_weigth_sum + weigthed_rating
  }
  single_user_median <- single_user_sum / nrow(single_user_dataset)
  single_user_weigth_median <- single_user_weigth_sum / nrow(single_user_dataset)
  single_user_mean_diff <- abs(single_user_weigth_median - single_user_median)
  users_dataset[user_index, 'mean'] <- single_user_median
  users_dataset[user_index, 'weigthed_mean'] <- single_user_weigth_median
  users_dataset[user_index, 'ratings_range'] <- single_user_time_range
  users_dataset[user_index, 'mean_diff'] <- single_user_mean_diff
}
```

Dopo aver effettuato tutti i calcoli, vediamo i risultati.
Il primo grafico che vediamo è relativo alle valutazioni all'interno del dataset.
```{r}
hist(
  rating_dataset[, 'rating'],
  breaks = 5,
  main = 'Frequency of registered ratings', 
  xlab = 'Ratings', 
  col = '#FDDBC7',
  border = '#F4A582'
)
```

I prossimi due grafici che vedremo rispettivamente la media aritmetica e la media pesata delle valutazioni:
```{r}
par(mfrow = c(1,2))
hist(
  users_dataset[, 'mean'],
  breaks = 5,
  main = 'Average non-weigthed mean ratings', 
  xlab = 'Mean ratings',
  col = '#4393C3',
  border = '#2166AC'
)
hist(
  users_dataset[, 'weigthed_mean'],
  breaks = 5,
  main = 'Average weigthed mean ratings', 
  xlab = 'Mean ratings',
  col = '#D6604D',
  border = '#B2182B'
)
```
Osservando i due grafici, notiamo che i valori assegnati alla media pesata sono  tendenzialmente più bassi.  

Il terzo grafico ci mostra l'andamento fra la differenze fra le media aritmetica ed il range temporale in cui sono state lasciate le valutazione.  

```{r}
plot(
  x = users_dataset[, 'ratings_range'], 
  y = users_dataset[, 'mean_diff'], 
  pch = 16, 
  xlab = 'Difference between last rating and first rating',
  ylab = 'Difference between weighted mean and mean',
  main = 'Correlation between ratings range and mean difference',
  col = '#F4A582'
)
```
Dal grafico, notiamo che all'aumentare della differenza temporale fra la prima e l'ultima valutazione, aumenta anche la differenza fra la media aritmetica e pesata.  
Possiamo dunque concludere che esiste una correlazione fra i due valori.

### Creazione dei sistemi di raccomandazione

Dopo aver ottenuto un dataset pulito, possiamo procedere alla creazione della matrice di utilità.  
Essendo il nostro dataset organizzato per righe, è necessario effettuare una conversione.  
Nel pacchetto reshape2 è inclusa la funzione `acast` che prendendo in input le liste di valori, la formula per creare righe / colonne e il nome della lista relativa valore da inserire nelle celle, ci restituisce una matrice.  
Nel nostro caso, `rating_dataset` rappresenta il dataset con tutte le colonne, `userId~movieId`rappresenta la formula per ottenere rispettivamente nelle righe gli utenti e nelle colonne i film, il valore `rating` rappresenta il valore nelle celle.   

Utilizziamola nel nostro caso:
```{r}
converted_matrix <- acast(rating_dataset, userId~movieId, value.var = "rating")
```

Adesso, la possiamo usare come oggetto di tipo `realRatingMatrix`, che reccomenderlab riconosce:
```{r}
rating_matrix <- as(converted_matrix, "realRatingMatrix")
```

Vediamo diversi modi per addestrare il sistema di raccomandazione:
```{r}
split_matrix <- evaluationScheme(
  data = rating_matrix, 
  method = "split", 
  train = 0.8, 
  given = given, 
  goodRating = 3, 
  k = 4
)
k_fold_matrix <- evaluationScheme(
  data = rating_matrix, 
  method = "cross-validation",
  k = 4, 
  given = given, 
  goodRating = 3
)
```

Di seguito, facciamo l'elenco dei metodi di valutazione che possiamo avere:
```{r}
models_list = list(
  "UBCF:Cosine:Split" = list(name="UBCF", data=split_matrix, params=list(method ="cosine", normalize="center")),
  "UBCF:Pearson:Split" = list(name="UBCF", data=split_matrix, params=list(method ="pearson", normalize="center")),
  "IBCF:Cosine:Split" = list(name="IBCF", data=split_matrix, params=list(method ="cosine", normalize="center")),
  "IBCF:Pearson:Split" = list(name="IBCF", data=split_matrix, params=list(method ="pearson", normalize="center")),
  "UBCF:Cosine:K-Fold" = list(name="UBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="center")),
  "UBCF:Pearson:K-Fold" = list(name="UBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="center")),
  "IBCF:Cosine:K-Fold" = list(name="IBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="center")),
  "IBCF:Pearson:K-Fold" = list(name="IBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="center")),
  "UBCF:Cosine:Split:Z" = list(name="UBCF", data=split_matrix, params=list(method ="cosine", normalize="z-score")),
  "UBCF:Pearson:Split:Z" = list(name="UBCF", data=split_matrix, params=list(method ="pearson", normalize="z-score")),
  "IBCF:Cosine:Split:Z" = list(name="IBCF", data=split_matrix, params=list(method ="cosine", normalize="z-score")),
  "IBCF:Pearson:Split:Z" = list(name="IBCF", data=split_matrix, params=list(method ="pearson", normalize="z-score")),
  "UBCF:Cosine:K-Fold:Z" = list(name="UBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="z-score")),
  "UBCF:Pearson:K-Fold:Z" = list(name="UBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="z-score")),
  "IBCF:Cosine:K-Fold:Z" = list(name="IBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="z-score")),
  "IBCF:Pearson:K-Fold:Z" = list(name="IBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="z-score"))
)
```

Creiamo una funzione per vedere gli errori:
```{r}
get_model_results <- function(settings) {
 model <- Recommender(getData(settings$data, "train"), settings$name, parameter = settings$params)
 test <- predict(model, getData(settings$data, "known"), type="ratings")
 error <- calcPredictionAccuracy(test, getData(settings$data, "unknown"))
 return(error)
}
```

Richiamiamola su tutti i metodi elencati fino ad ora:
```{r}
for (model_name in names(models_list)) {
  settings <- models_list[[model_name]]
  model_error <- get_model_results(settings)
  models_list[[model_name]] <- c(settings, results=model_error)
}
```

Elenchiamo i risultati:
```{r}
for (model_name in names(models_list)) {
  print(paste("Printing results for:", model_name))
  print(paste("RSME:", models_list[[model_name]]$results.RMSE))
  print(paste("MSE:", models_list[[model_name]]$results.MSE))
  print(paste("MAE:", models_list[[model_name]]$results.MAE))
}
```

Vedi altre risorse:  
- [Reccomendation 101](https://www.r-bloggers.com/2014/12/recommender-systems-101-a-step-by-step-practical-example-in-r/)  
- [Data Mania](https://www.data-mania.com/blog/how-to-build-a-recommendation-engine-in-r/)  
- [Res 1](https://rpubs.com/robertwsellers/IS643_Project_2)   
- [Res 2](https://rpubs.com/dhairavc/628480)  
- [Res 3](https://www.linkedin.com/pulse/create-recommendation-engine-using-r-simple-steps-minta-thomas/)  
- [Weigth median](https://stats.stackexchange.com/questions/196653/assigning-more-weight-to-more-recent-observations-in-regression)