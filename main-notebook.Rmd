---
title: "Sistemi di raccomandazione in R"
output: html_notebook
---

### Introduzione
I **sistemi di raccomandazione** sono dei sistemi software che permettono di predire le preferenze di un utente basandoci sulle preferenze espresse dall'utente in passato.  
A differenza dei sistemi tradizionali, essi possono predire il gradimento dell'utente anche per oggetti rari, evitando il cosiddetto fenomeno **long-tail**.  
Un sistema di raccomandazione è strutturato in una matrice chiamata **matrice di utilità**, avente:  
- nelle righe, gli utenti del sistema.  
- nelle colonne, gli oggetti da valutare.  
- nelle celle, la valutazione dell'oggetto nella colonna `j` relativa all'utente nella riga `i`.  

I sistemi di raccomandazione possono diversi in due categorie:  
-  **content-based**: ad ogni utente è associato un profilo che verrà utilizzato per effettuare le predizioni sugli item.  
- **collaborative-filtering**: le predizioni sugli item vengono fatte basandoci su utenti simili (nel caso di **user-based** collaborative filtering) oppure su item simili (nel caso di **item-based** collaborative filtering).  

### Obbiettivo
Creeremo diversi sistemi di raccomandazione e ne confronteremo le prestazioni. Useremo anche un sistema personalizzato che tenga in considerazione delle data in cui è stata lasciata la valutazione.  
Useremo questo [dataset](https://grouplens.org/datasets/movielens/1m/) per generare i sistemi. Al suo interno sono presenti due tabelle `.csv`:  
- `movies.csv`: contiene l'elenco dei film, con i campi `movieId`, `title` e `genres`.  
- `ratings.csv`: contiene l'elenco delle valutazione relative agli utenti, con i campi `userId`, `movieId`, `rating`, `timestamp`.  
- `users.csv`: contiene l'elenco degli utenti e le loro informazioni, con i campi `userId`, `gender`, `age`, `occupation`, `zip`.  

### Preparazione dell'ambiente
All'interno del nostro progetto, useremo diverse librerie:  
- [`reshape2`](https://cran.r-project.org/web/packages/reshape2/index.html), permette di creare un data frame oppure una matrice partendo da una lista.  
- [`reccomenderlab`](https://cran.r-project.org/web/packages/recommenderlab/index.html), permette la creazione e la valutazione dei sistemi di raccomandazione.  
- [`sqldf`](https://cran.r-project.org/web/packages/sqldf/index.html), permette la manipolazione di data frame usando la sintassi SQL.  

Importiamo i pacchetti all'interno del progetto:
```{r}
library("reshape2")
library("recommenderlab")
library("sqldf")
```
Adesso, carichiamo i dataset all'interno del progetto usando la funzione `read.csv`:
```{r}
movie_dataset <- read.csv("movie-dataset/movies.csv",  sep = "+")
rating_dataset <- read.csv("movie-dataset/ratings.csv", sep = "+")
```

### Pulizia del dataset

Una volta caricati i dati, verifichiamone l'**integrità**.  
L'integrità dei dati è essenziale per garantire l'affidabilità dei risultati dell'analisi.  
La presenza di dati incompleti, come i valori `NA`, potrebbero influenzare la validità dei risultati dell'analisi.  
All'interno di R è presente la funzione `complete.cases` che restituisce una matrice di valori booleani con:  
- TRUE, nel caso in cui i dati sono completi.  
- FALSE, nel caso in cui i dati sono incompleti.  
Questa funzione può essere usata per effettuare una **pulizia** sui dati:
```{r}
movie_dataset <- movie_dataset[complete.cases(movie_dataset), ]
rating_dataset <- rating_dataset[complete.cases(rating_dataset), ]
```

Scartati i dati nulli o incompleti, prendiamo in considerazione solo una porzione dei dati, in particolare consideriamo solo:  
- gli utenti che hanno valutato **almeno 300 film**.  
- i film che sono stati valutati **almeno 600 volte**.  
Questo condizione ci permette di escludere utenti e film che non sono stati valutati abbastanza e per cui **non sono presenti abbastanza dati per poter effettuare predizioni sufficientemente accurate**.  
Filtriamo quindi il dataset delle valutazione in base alle condizione sopra citate:  
```{r}
grouped_users <- sqldf("SELECT userId, COUNT(movieId) as count_user FROM rating_dataset GROUP BY userId")
grouped_movies <- sqldf("SELECT movieId, COUNT(userId) as count_movie FROM rating_dataset GROUP BY movieId")
rating_dataset <- sqldf(
  "SELECT rating_dataset.userId, rating_dataset.movieId, rating, timestamp, count_user, count_movie FROM rating_dataset 
   LEFT JOIN grouped_users ON grouped_users.userId = rating_dataset.userId
   LEFT JOIN grouped_movies ON grouped_movies.movieId = rating_dataset.movieId
   WHERE count_user > 300 AND count_movie > 600
  "
)
given <- 240
```

### Analisi del dataset

Dopo un primo filtro, possiamo caricare i dati relativi agli utenti:
```{r}
users_dataset <- read.csv('movie-dataset/users.csv', sep = '+')
```

Da questi, leviamo gli utenti che non sono più inclusi nelle valutazioni:
```{r}
users_dataset <- sqldf("
  SELECT userId, gender, age, occupation, zip FROM users_dataset
  WHERE userId IN (SELECT DISTINCT(userId) FROM rating_dataset)
")
```

Una volta rimosso dal dataset degli utenti che non hanno fatto recensito abbastanza film, aggiungiamo al data frame le seguenti colonne:  
- `mean`, contiene la media delle valutazione lasciate dall'utente.  
- `weighted_mean`, contiene la media pesata con il timestamp delle valutazioni lasciate dall'utente.  
- `ratings_range`, contiene la differenza fra la prima valutazione e l'ultima valutazione lasciata dall'utente.  
- `mean_diff`, contiene la differenza fra la media aritmetica e la media pesata delle valutazioni.  

Gli ultimi due campi ci permetteranno di dimostrare se esiste una correlazione fra la differenze fra le media aritmetica ed il range temporale in cui sono state lasciate le valutazione.  
In pratica, vogliamo verificare se in un intervallo temporale più ampio, la differenza fra la media aritmetica e quella pesata aumenta.

```{r}
users_dataset['mean'] <- replicate(nrow(users_dataset), 0)
users_dataset['weigthed_mean'] <- replicate(nrow(users_dataset), 0)
users_dataset['ratings_range'] <- replicate(nrow(users_dataset), 0)
users_dataset['mean_diff'] <- replicate(nrow(users_dataset), 0)
```

Una volta aggiunti i campi, effettuiamo tutti i calcoli necessari per popolare i campi:
```{r}
map_range <- function(x, min_val, max_val, new_min = 0.5, new_max = 1.5) {
  y <- (x - min_val) * (new_max - new_min) / (max_val - min_val) + new_min
  return(y)
}


for (user_index in 1:nrow(users_dataset)) {
  user <- users_dataset[user_index, 'userId']
  single_user_dataset <- rating_dataset[rating_dataset[, 'userId'] == user, ]
  single_user_first_rating <- min(single_user_dataset[, 'timestamp'])
  single_user_last_rating <- max(single_user_dataset[, 'timestamp'])
  single_user_time_range <- single_user_last_rating - single_user_first_rating
  single_user_ratings <- single_user_dataset[, 'rating']
  single_user_weigths <- sapply(
    single_user_dataset[, 'timestamp'], 
    function (x) map_range(x, single_user_first_rating, single_user_last_rating)
  )
  single_user_mean <- mean(single_user_ratings)
  single_user_weight_mean <- weighted.mean(single_user_ratings, single_user_weigths)
  single_user_mean_diff <- abs(single_user_weight_mean - single_user_mean)
  users_dataset[user_index, 'mean'] <- single_user_mean
  users_dataset[user_index, 'weigthed_mean'] <- single_user_weight_mean
  users_dataset[user_index, 'ratings_range'] <- single_user_time_range
  users_dataset[user_index, 'mean_diff'] <- single_user_mean_diff
}
```

Dopo aver effettuato tutti i calcoli, vediamo i risultati.
Il primo grafico che vediamo è relativo alle valutazioni all'interno del dataset.
```{r}
hist(
  rating_dataset[, 'rating'],
  breaks = 5,
  main = 'Frequency of registered ratings', 
  xlab = 'Ratings', 
  col = '#FDDBC7',
  border = '#F4A582'
)
```

I prossimi due grafici che vedremo rispettivamente la media aritmetica e la media pesata delle valutazioni:
```{r}
par(mfrow = c(1,2))
hist(
  users_dataset[, 'mean'],
  breaks = 5,
  main = 'Average non-weigthed mean ratings', 
  xlab = 'Mean ratings',
  col = '#4393C3',
  border = '#2166AC'
)
hist(
  users_dataset[, 'weigthed_mean'],
  breaks = 5,
  main = 'Average weigthed mean ratings', 
  xlab = 'Mean ratings',
  col = '#D6604D',
  border = '#B2182B'
)
```
Osservando i due grafici, notiamo che i valori assegnati alla media pesata sono  tendenzialmente più bassi.  

Il terzo grafico ci mostra l'andamento fra la differenze fra le media aritmetica ed il range temporale in cui sono state lasciate le valutazione.  

```{r}
plot(
  x = users_dataset[, 'ratings_range'], 
  y = users_dataset[, 'mean_diff'], 
  pch = 16, 
  xlab = 'Difference between last rating and first rating',
  ylab = 'Difference between weighted mean and mean',
  main = 'Correlation between ratings range and mean difference',
  col = '#F4A582'
)
```
Dal grafico, notiamo che i valori si concentrano principalmente sulla parte bassa del grafico. Ciò significa che non è detto che all'aumentare della variazione della media corrisponda un aumento del range temporale.

### Creazione dei sistemi di raccomandazione

Dopo aver ottenuto un dataset pulito, possiamo procedere alla creazione della matrice di utilità.  
Essendo il nostro dataset organizzato per righe, è necessario effettuare una conversione.  
Nel pacchetto reshape2 è inclusa la funzione `acast` che prendendo in input le liste di valori, la formula per creare righe / colonne e il nome della lista relativa valore da inserire nelle celle, ci restituisce una matrice.  
Nel nostro caso, `rating_dataset` rappresenta il dataset con tutte le colonne, `userId~movieId`rappresenta la formula per ottenere rispettivamente nelle righe gli utenti e nelle colonne i film, il valore `rating` rappresenta il valore nelle celle.   

Utilizziamola nel nostro caso:
```{r}
converted_matrix <- acast(rating_dataset, userId~movieId, value.var = "rating")
```

Adesso, la possiamo usare come oggetto di tipo `realRatingMatrix`, che reccomenderlab riconosce:
```{r}
rating_matrix <- as(converted_matrix, "realRatingMatrix")
```

`reccomenderlab` supporta diversi modi per addestrare il sistema di raccomandazione:  
- **Split**, implica la suddivisione del dataset in due parti, una per il training e l'altra per il testing. Generalmente, si divide il dataset in modo che il 70-80% dei dati siano utilizzati per il training e il restante 20-30% per il testing. Questa tecnica è semplice e veloce da implementare, tuttavia, la scelta di come suddividere il dataset in training e testing può influenzare significativamente l'accuratezza del modello.  
- **Bootstrap**, prevede di creare diverse ripetizioni del dataset (sampling con ripetizione) e di selezionare casualmente il training e il test set in ogni ripetizione. In questo modo, ogni osservazione ha la stessa probabilità di essere selezionata per il training set o il test set in ogni ripetizione.   
- **Cross Validation** (validazione incrociata), prevede di suddividere il dataset in k parti uguali, chiamate fold. Il modello viene poi addestrato su k-1 fold e testato sul fold rimanente. Questo processo viene ripetuto k volte, utilizzando un fold differente come test set ad ogni ripetizione. In questo modo, ogni osservazione viene utilizzata sia per il training che per il testing. Questa tecnica può essere utile per valutare il modello in modo più accurato, riducendo l'effetto della scelta casuale dei dati di training e testing.   

Creiamo quindi i diversi schemi che utilizzeremo in sequenza:
```{r}
split_matrix <- evaluationScheme(
  data = rating_matrix, 
  method = "split", 
  train = 0.8, 
  given = given, 
  goodRating = 3
)
bootstrap_matrix <- evaluationScheme(
  data = rating_matrix, 
  method = "bootstrap",
  given = given, 
  goodRating = 3
)
k_fold_matrix <- evaluationScheme(
  data = rating_matrix, 
  method = "cross-validation",
  k = 8, 
  given = given, 
  goodRating = 3
)
```

Dopo aver generato i possibili modi per addestrare il sistema di raccomandazione, creiamo i modelli che addestreremo.  
`reccomenderlab` ci permette di impostare diversi parametri nella creazione di un modello, fra cui:  
- `name`, indica come `reccomenderlab` gestisce il tipo di sistema di raccomandazione.  
- `method`, indica la formula matematica usata per misurare la similarità fra due insiemi di dati.  
- `normalize`, indica la formula matematica usata per normalizzare la matrice di utilità del sistema di raccomandazione.  

Come tipologia di sistemi, quindi come `name`, useremo:  
- **UBCF** (User Based Collaborative Filtering).  
- **IBCF** (Item Based Collaborative Filtering).  

Come formula per valutare la similarità fra due insieme di dati, useremo:  
- **Similarità del coseno**:
$$
\text{cossim}(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x} \cdot \mathbf{y}}{|\mathbf{x}| |\mathbf{y}|}
$$
- **Correlazione di Pearson**:
$$
\text{correlation}(X, Y) = \frac{\text{cov}(X, Y)}{\text{std}(X) \cdot \text{std}(Y)}
$$
Entrambe le misure ritornano un valore da -1 ad 1, dove al valore -1 corrisponde una similarità nulla, mentre al valore 1 corrisponde una similarità totale.

Come misure di normalizzazione, quindi come `normalize`, useremo:  
- **Center**:
$$
r'_{u,i} = r_{u,i} - \mu_u
$$
- **Z-Score**:
$$
r'_{u,i} = \frac{r_{u,i} - \mu_u}{\sigma_u}
$$
La principale differenza sta nel calcolo: mentre la normalizzazione center calcola semplicemente la media delle valutazione e le sottrae al rating dell'oggetto $i$ relativo all'utente $u$, la normalizzazione z-score divide tutto per la deviazione standard.

Dopo aver elencato tutti i possibili parametri, generiamo i singoli modelli, assegnandoli ad una lista diversa in base al modo in cui i dati assegnati ad essi sono stati suddivisi:
```{r}
models_split_list <- list(
  "UBCF:Cosine:Center" = list(name="UBCF", data=split_matrix, params=list(method ="cosine", normalize="center")),
  "UBCF:Pearson:Center" = list(name="UBCF", data=split_matrix, params=list(method ="pearson", normalize="center")),
  "IBCF:Cosine:Center" = list(name="IBCF", data=split_matrix, params=list(method ="cosine", normalize="center")),
  "IBCF:Pearson:Center" = list(name="IBCF", data=split_matrix, params=list(method ="pearson", normalize="center")),
  "UBCF:Cosine:Z-Score" = list(name="UBCF", data=split_matrix, params=list(method ="cosine", normalize="z-score")),
  "UBCF:Pearson:Z-Score" = list(name="UBCF", data=split_matrix, params=list(method ="pearson", normalize="z-score")),
  "IBCF:Cosine:Z-Score" = list(name="IBCF", data=split_matrix, params=list(method ="cosine", normalize="z-score")),
  "IBCF:Pearson:Z-Score" = list(name="IBCF", data=split_matrix, params=list(method ="pearson", normalize="z-score"))
)

models_bootstrap_list <- list(
  "UBCF:Cosine:Center" = list(name="UBCF", data=bootstrap_matrix, params=list(method ="cosine", normalize="center")),
  "UBCF:Pearson:Center" = list(name="UBCF", data=bootstrap_matrix, params=list(method ="pearson", normalize="center")),
  "IBCF:Cosine:Center" = list(name="IBCF", data=bootstrap_matrix, params=list(method ="cosine", normalize="center")),
  "IBCF:Pearson:Center" = list(name="IBCF", data=bootstrap_matrix, params=list(method ="pearson", normalize="center")),
  "UBCF:Cosine:Z-Score" = list(name="UBCF", data=bootstrap_matrix, params=list(method ="cosine", normalize="z-score")),
  "UBCF:Pearson:Z-Score" = list(name="UBCF", data=bootstrap_matrix, params=list(method ="pearson", normalize="z-score")),
  "IBCF:Cosine:Z-Score" = list(name="IBCF", data=bootstrap_matrix, params=list(method ="cosine", normalize="z-score")),
  "IBCF:Pearson:Z-Score" = list(name="IBCF", data=bootstrap_matrix, params=list(method ="pearson", normalize="z-score"))
)

models_k_fold_list <- list(
  "UBCF:Cosine:Center" = list(name="UBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="center")),
  "UBCF:Pearson:Center" = list(name="UBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="center")),
  "IBCF:Cosine:Center" = list(name="IBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="center")),
  "IBCF:Pearson:Center" = list(name="IBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="center")),
  "UBCF:Cosine:Z-Score" = list(name="UBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="z-score")),
  "UBCF:Pearson:Z-Score" = list(name="UBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="z-score")),
  "IBCF:Cosine:Z-Score" = list(name="IBCF", data=k_fold_matrix, params=list(method ="cosine", normalize="z-score")),
  "IBCF:Pearson:Z-Score" = list(name="IBCF", data=k_fold_matrix, params=list(method ="pearson", normalize="z-score"))
)
```

Creiamo una funzione per addestrare il sistema e valutarne gli errori sul test set:
```{r}
trainModel <- function(settings) {
 model <- Recommender(getData(settings$data, "train"), settings$name, parameter = settings$params)
 test <- predict(model, getData(settings$data, "known"), type="ratings")
 error <- calcPredictionAccuracy(test, getData(settings$data, "unknown"))
 return(error)
}
```

Creiamo una funzione per addestrare tutti i sistemi di una lista:
```{r}
trainModels <- function(models_list) {
  for (model_name in names(models_list)) {
    settings <- models_list[[model_name]]
    model_error <- trainModel(settings)
    models_list[[model_name]] <- c(settings, results = model_error)
  }
  return(models_list)
}
```

Richiamiamola sulle liste generate:
```{r}
models_split_list <- trainModels(models_split_list)
models_bootstrap_list <- trainModels(models_bootstrap_list)
models_k_fold_list <- trainModels(models_k_fold_list)
```


Organizziamo i dati salvati dall'addestramento in un data frame:
```{r}
models_split_results <- data.frame(
  rmse = sapply(models_split_list, '[[', 'results.RMSE'),
  mse = sapply(models_split_list, '[[', 'results.MSE'),
  mae = sapply(models_split_list, '[[', 'results.MAE')
)
models_bootstrap_results <- data.frame(
  rmse = sapply(models_bootstrap_list, '[[', 'results.RMSE'),
  mse = sapply(models_bootstrap_list, '[[', 'results.MSE'),
  mae = sapply(models_bootstrap_list, '[[', 'results.MAE')
)
models_k_fold_results <- data.frame(
  rmse = sapply(models_k_fold_list, '[[', 'results.RMSE'),
  mse = sapply(models_k_fold_list, '[[', 'results.MSE'),
  mae = sapply(models_k_fold_list, '[[', 'results.MAE')
)

models_split_results
models_bootstrap_results
models_k_fold_results
```

E calcoliamo la media degli errori:
```{r}
models_mean_error <- data.frame(
  rmse = c(
    mean(models_split_results[, 'rmse']),
    mean(models_bootstrap_results[, 'rmse']),
    mean(models_k_fold_results[, 'rmse'])
  ),
  mse = c(
    mean(models_split_results[, 'mse']),
    mean(models_bootstrap_results[, 'mse']),
    mean(models_k_fold_results[, 'mse'])
  ),
  mae = c(
    mean(models_split_results[, 'mae']),
    mean(models_bootstrap_results[, 'mae']),
    mean(models_k_fold_results[, 'mae'])
  )
)
rownames(models_mean_error) <- c('Split method', 'Bootstrap method', 'Cross validation method')

models_mean_error
```

### Normalizzazione temporale
All'interno di un sistema di raccomandazione, potremmo anche normalizzare secondo una funzione personalizzata. Come abbiamo visto prima, con l'utilizzo dei timestamp, possiamo ricavare una media pesata in cui diamo un peso minore alla valutazione meno recenti ed un peso maggiore alle valutazione più recenti.  
Affinché R possa creare un sistema personalizzato, occorre creare una funzione `normalize` personalizzata che chiameremo `weight_normalize`.  
La funzione necessita di un matrice di timestamp, da usare come media pesata:
```{r}
timestamp_matrix <- acast(rating_dataset, userId~movieId, value.var = "timestamp")
```
Inoltre, è necessario che i timestamp vadano normalizzati all'interno di un certo intervallo. Il nostro intervallo andrà da `0.5` a `1.5`. Per effettuare questa operazione, creiamo una funzione chiamata `timestamp_normalize`:
```{r}
timestamp_normalize <- function(matrix_input) {
  n_rows <- nrow(matrix_input)
  n_cols <- ncol(matrix_input)
  
  for (i in 1:n_rows) {
    row_i <- matrix_input[i, ]
    
    min_i <- min(row_i, na.rm = TRUE)
    max_i <- max(row_i, na.rm = TRUE)
    
    for (j in 1:n_cols) {
      if (!is.na(matrix_input[i, j])) {
       matrix_input[i, j] = map_range(matrix_input[i, j], min_i, max_i) 
      }
    }
  }

  return(matrix_input)
}

```

e applichiamola sulla matrice dei timestamp:
```{r}
timestamp_matrix <- timestamp_normalize(timestamp_matrix)
```

A questo punto, possiamo creare la funzione `weight_normalize` che genera la media pesata e ritorna una matrice normalizzata subito utilizzabile:
```{r}
weight_normalize <- function(x, y, row = TRUE) {
  n_rows = nrow(x)
  n_cols = ncol(x)
  
  if (n_rows != nrow(y)) {
    warning("Matrixes must have same rows number")
    return(x)
  }
  if (n_cols != ncol(y)) {
    warning("Matrixes must have same columns number")
    return(x)
  }
  
  matrix_output <- matrix(NA, nrow = n_rows, ncol = n_cols)
  rownames(matrix_output) <- rownames(x)
  colnames(matrix_output) <- colnames(x)
  
  means <- list()
  
  if (row) {
    for (i in 1:n_rows) {
      values_raw = x[i, ]
      values = values_raw[!is.na(values_raw)]
      weights_raw = y[i, ]
      weights = weights_raw[!is.na(weights_raw)]
      weight_mean = weighted.mean(values, weights)
      means[[i]] <- weight_mean
      
      for (j in 1:n_cols) {
        if (!is.na(x[i, j])) {
         matrix_output[i, j] = x[i, j] - weight_mean
        }
      }
    }
  } else {
    for (i in 1:n_cols) {
      values_raw = x[, i]
      values = values_raw[!is.na(values_raw)]
      weights_raw = y[, i]
      weights = weights_raw[!is.na(weights_raw)]
      weight_mean = weighted.mean(values, weights)
      
      for (j in 1:n_rows) {
        if (!is.na(x[j, i])) {
         matrix_output[j, i] = x[j, i] - weight_mean
        }
      }
    }
  }
  
  normalized <- as(matrix_output, "realRatingMatrix")
  normalize_field <- if (row) "row" else "col"
  normalized@normalize[[normalize_field]] <- list(method='weight', factors=list(means=means, sds=NULL))
  return(normalized)
}
```
Generiamo dunque la nostra matrice:
```{r}
weighted_matrix <- weight_normalize(converted_matrix, timestamp_matrix)
```


Vedi altre risorse:  
- [Reccomendation 101](https://www.r-bloggers.com/2014/12/recommender-systems-101-a-step-by-step-practical-example-in-r/)  
- [Data Mania](https://www.data-mania.com/blog/how-to-build-a-recommendation-engine-in-r/)  
- [Res 1](https://rpubs.com/robertwsellers/IS643_Project_2)   
- [Res 2](https://rpubs.com/dhairavc/628480)  
- [Res 3](https://www.linkedin.com/pulse/create-recommendation-engine-using-r-simple-steps-minta-thomas/)  
- [Weigth median](https://stats.stackexchange.com/questions/196653/assigning-more-weight-to-more-recent-observations-in-regression)